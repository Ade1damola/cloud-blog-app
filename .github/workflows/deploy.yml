# GitHub Actions Workflow
name: Deploy Cloud Blog

# When to run this workflow
on:
  push:
    branches: [ main ]
    # Run on every push to main branch
  
  pull_request:
    branches: [ main ]
    # Run on pull requests to main

# Environment variables available to all jobs
env:
  AWS_REGION: us-east-1
  DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}

# Jobs to run
jobs:
  
  # Job 1: Test Application
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    # Run on Ubuntu Linux
    
    steps:
      # Step 1: Check out code
      - name: Checkout code
        uses: actions/checkout@v4
        # Download repository code
      
      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          pip install -r backend/requirements.txt
          pip install -r frontend/requirements.txt
      
      # Step 4: Run basic syntax check
      - name: Check Python syntax
        run: |
          python -m py_compile backend/app.py
          python -m py_compile frontend/app.py
        # py_compile: Check for syntax errors
  
  # Job 2: Security Scanning
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: test
    # Run after test job completes
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Scan Terraform code
      - name: Run tfsec
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform
          soft_fail: true
          # soft_fail: Show issues but don't fail build
      
      # Scan Docker images
      - name: Build Docker images
        run: |
          docker build -t backend:test backend/
          docker build -t frontend:test frontend/
      
      - name: Run Trivy scan on Backend
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: backend:test
          format: 'table'
          exit-code: '0'
          # Don't fail on vulnerabilities (just report)
      
      - name: Run Trivy scan on Frontend
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: frontend:test
          format: 'table'
          exit-code: '0'
  
  # Job 3: Build and Push Docker Images
  build:
    name: Build and Push Images
    runs-on: ubuntu-latest
    needs: security-scan
    # Only run on main branch
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Log in to Docker Hub
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      # Build and push backend image
      - name: Build and push backend
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/cloud-blog-backend:latest
      
      # Build and push frontend image
      - name: Build and push frontend
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/cloud-blog-frontend:latest
  
  # Job 4: Deploy Infrastructure
  deploy:
    name: Deploy to AWS
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      # Set up Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      # Initialize Terraform
      - name: Terraform Init
        working-directory: terraform
        run: terraform init
      
      # Plan infrastructure changes
      - name: Terraform Plan
        working-directory: terraform
        run: |
          terraform plan \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="docker_username=${{ secrets.DOCKER_USERNAME }}" \
            -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}"
      
      # Apply infrastructure changes
      - name: Terraform Apply
        working-directory: terraform
        run: |
          terraform apply -auto-approve \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="docker_username=${{ secrets.DOCKER_USERNAME }}" \
            -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}"
      
      # Get outputs
      - name: Get Terraform Outputs
        working-directory: terraform
        run: |
          echo "EC2_IP=$(terraform output -raw ec2_private_ip)" >> $GITHUB_ENV
          echo "DB_ENDPOINT=$(terraform output -raw database_endpoint)" >> $GITHUB_ENV
          echo "DB_NAME=$(terraform output -raw database_name)" >> $GITHUB_ENV
      
# Deploy application to EC2
      - name: Deploy Application
        env:
          DB_ENDPOINT: ${{ env.DB_ENDPOINT }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        run: |
          # Get EC2 instance ID
          INSTANCE_ID=$(cd terraform && terraform output -raw ec2_instance_id)
          
          # Extract database host from endpoint
          DB_HOST=$(echo $DB_ENDPOINT | cut -d: -f1)
          
          # Create docker-compose content
          COMPOSE_CONTENT=$(cat << 'EOF'
          version: '3.8'
          services:
            backend:
              image: DOCKER_USERNAME_PLACEHOLDER/cloud-blog-backend:latest
              ports:
                - "5000:5000"
              environment:
                DB_HOST: DB_HOST_PLACEHOLDER
                DB_NAME: blogdb
                DB_USER: postgres
                DB_PASSWORD: DB_PASSWORD_PLACEHOLDER
              restart: always
            
            frontend:
              image: DOCKER_USERNAME_PLACEHOLDER/cloud-blog-frontend:latest
              ports:
                - "8080:8080"
              environment:
                BACKEND_URL: http://backend:5000
              depends_on:
                - backend
              restart: always
          EOF
          )
          
          # Replace placeholders
          COMPOSE_CONTENT="${COMPOSE_CONTENT//DOCKER_USERNAME_PLACEHOLDER/$DOCKER_USERNAME}"
          COMPOSE_CONTENT="${COMPOSE_CONTENT//DB_HOST_PLACEHOLDER/$DB_HOST}"
          COMPOSE_CONTENT="${COMPOSE_CONTENT//DB_PASSWORD_PLACEHOLDER/$DB_PASSWORD}"
          
          # Create deployment script
          DEPLOY_SCRIPT=$(cat << 'SCRIPT'
          #!/bin/bash
          set -e
          
          # Navigate to app directory
          cd /home/ec2-user/app
          
          # Stop existing containers
          if [ -f docker-compose.yml ]; then
            docker-compose down || true
          fi
          
          # Write new docker-compose file
          cat > docker-compose.yml << 'COMPOSEEOF'
          COMPOSE_CONTENT_PLACEHOLDER
          COMPOSEEOF
          
          # Pull latest images
          docker-compose pull
          
          # Start containers
          docker-compose up -d
          
          # Show status
          docker-compose ps
          SCRIPT
          )
          
          # Replace compose content in script
          DEPLOY_SCRIPT="${DEPLOY_SCRIPT//COMPOSE_CONTENT_PLACEHOLDER/$COMPOSE_CONTENT}"
          
          # Save script to file
          echo "$DEPLOY_SCRIPT" > deploy_script.sh
          
          # Send script to EC2 using SSM
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters commands="$(cat deploy_script.sh)" \
            --output text \
            --query "Command.CommandId" > command_id.txt
          
          COMMAND_ID=$(cat command_id.txt)
          echo "Command ID: $COMMAND_ID"
          
          # Wait for command to complete
          for i in {1..30}; do
            STATUS=$(aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "$INSTANCE_ID" \
              --query "Status" \
              --output text)
            
            echo "Status: $STATUS"
            
            if [ "$STATUS" = "Success" ]; then
              echo "Deployment successful!"
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "$INSTANCE_ID" \
                --query "StandardOutputContent" \
                --output text
              exit 0
            elif [ "$STATUS" = "Failed" ]; then
              echo "Deployment failed!"
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "$INSTANCE_ID" \
                --query "StandardErrorContent" \
                --output text
              exit 1
            fi
            
            sleep 10
          done
          
          echo "Deployment timeout"
          exit 1